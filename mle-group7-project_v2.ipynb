{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e215ec-7c6a-425d-a2ad-fe3a4b9e9479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07761a4a-721c-4fc9-98c2-1498f1f3b466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==2.159.0 in /opt/conda/lib/python3.7/site-packages (2.159.0)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (0.3.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (3.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (1.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (4.13.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (0.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (1.3.5)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (1.26.155)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (0.1.5)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (0.7.5)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (23.1.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (1.7.0)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (6.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (3.20.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.159.0) (1.21.6)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker==2.159.0) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.155 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker==2.159.0) (1.29.155)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.26.131->sagemaker==2.159.0) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.159.0) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.159.0) (4.5.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.159.0) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.159.0) (2.4.6)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.159.0) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema->sagemaker==2.159.0) (59.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.159.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker==2.159.0) (2019.3)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.159.0) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.159.0) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.159.0) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker==2.159.0) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker==2.159.0) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.155->boto3<2.0,>=1.26.131->sagemaker==2.159.0) (1.26.15)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"sagemaker==2.159.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ef36bac-9208-439b-b4a9-ba58a0bea2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import pathlib\n",
    "import io\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput, \n",
    "    ProcessingOutput, \n",
    "    ScriptProcessor\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep, \n",
    "    TrainingStep, \n",
    "    CreateModelStep\n",
    ")\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger, \n",
    "    ParameterFloat, \n",
    "    ParameterString, \n",
    "    ParameterBoolean\n",
    ")\n",
    "from sagemaker.workflow.clarify_check_step import (\n",
    "    ModelBiasCheckConfig, \n",
    "    ClarifyCheckStep, \n",
    "    ModelExplainabilityCheckConfig\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource, \n",
    "    ModelMetrics, \n",
    "    FileSource\n",
    ")\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd087919-d4ab-4ee3-af1f-8a4e48546f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate AWS services session and client objects\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = 'stroke-prediction'\n",
    "# write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Fetch SageMaker execution role\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "# read_bucket = \"sagemaker-sample-files\"\n",
    "# read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "read_bucket = \"mle-group7-project\"\n",
    "read_prefix = \"data\"\n",
    "\n",
    "# S3 location where raw data to be fetched from\n",
    "raw_data_key = f\"{write_bucket}/{read_bucket}/{read_prefix}\"\n",
    "\n",
    "# S3 location where processed data to be uploaded\n",
    "processed_data_key = f\"{write_prefix}/processed\"\n",
    "\n",
    "# S3 location where train data to be uploaded\n",
    "train_data_key = f\"{write_prefix}/train\"\n",
    "\n",
    "# S3 location where validation data to be uploaded\n",
    "validation_data_key = f\"{write_prefix}/validation\"\n",
    "\n",
    "# S3 location where test data to be uploaded\n",
    "test_data_key = f\"{write_prefix}/test\"\n",
    "\n",
    "\n",
    "# Full S3 paths\n",
    "data_uri = f\"s3://{raw_data_key}/healthcare-dataset-stroke-data.csv\"\n",
    "output_data_uri = f\"s3://{write_bucket}/{write_prefix}/\"\n",
    "scripts_uri = f\"s3://{write_bucket}/{write_prefix}/code\"\n",
    "estimator_output_uri = f\"s3://{write_bucket}/{write_prefix}/training_jobs\"\n",
    "processing_output_uri = f\"s3://{write_bucket}/{write_prefix}/processing_jobs\"\n",
    "model_eval_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_eval\"\n",
    "clarify_bias_config_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_monitor/bias_config\"\n",
    "clarify_explainability_config_output_uri = f\"s3://{write_bucket}/{write_prefix}/model_monitor/explainability_config\"\n",
    "bias_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify_output/pipeline/bias\"\n",
    "explainability_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify_output/pipeline/explainability\"\n",
    "\n",
    "# Retrieve training image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\", py_version=\"py3\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "971391ef-6164-404e-819e-98bd0f075467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set names of pipeline objects\n",
    "pipeline_name = \"StrokeXGBPipeline\"\n",
    "pipeline_model_name = \"stroke-prediction-xgb-pipeline\"\n",
    "model_package_group_name = \"stroke-prediction-xgb-model-group\"\n",
    "base_job_name_prefix = \"stroke-prediction\"\n",
    "endpoint_config_name = f\"{pipeline_model_name}-endpoint-config\"\n",
    "endpoint_name = f\"{pipeline_model_name}-endpoint\"\n",
    "\n",
    "# Set data parameters\n",
    "target_col = \"stroke\"\n",
    "\n",
    "# Set instance types and counts\n",
    "process_instance_type = \"ml.c5.xlarge\"\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.m4.xlarge\"\n",
    "clarify_instance_count = 1\n",
    "clarify_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58056ac8-9526-43f7-8a0c-066bdf4d90ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up pipeline input parameters\n",
    "\n",
    "# Set processing instance type\n",
    "process_instance_type_param = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=process_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance type\n",
    "train_instance_type_param = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=train_instance_type,\n",
    ")\n",
    "\n",
    "# Set training instance count\n",
    "train_instance_count_param = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=train_instance_count\n",
    ")\n",
    "\n",
    "# Set deployment instance type\n",
    "deploy_instance_type_param = ParameterString(\n",
    "    name=\"DeployInstanceType\",\n",
    "    default_value=predictor_instance_type,\n",
    ")\n",
    "\n",
    "# Set deployment instance count\n",
    "deploy_instance_count_param = ParameterInteger(\n",
    "    name=\"DeployInstanceCount\",\n",
    "    default_value=predictor_instance_count\n",
    ")\n",
    "\n",
    "# Set Clarify check instance type\n",
    "clarify_instance_type_param = ParameterString(\n",
    "    name=\"ClarifyInstanceType\",\n",
    "    default_value=clarify_instance_type,\n",
    ")\n",
    "\n",
    "# Set model bias check params\n",
    "skip_check_model_bias_param = ParameterBoolean(\n",
    "    name=\"SkipModelBiasCheck\", \n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "register_new_baseline_model_bias_param = ParameterBoolean(\n",
    "    name=\"RegisterNewModelBiasBaseline\",\n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "supplied_baseline_constraints_model_bias_param = ParameterString(\n",
    "    name=\"ModelBiasSuppliedBaselineConstraints\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "# # Set model explainability check params\n",
    "skip_check_model_explainability_param = ParameterBoolean(\n",
    "    name=\"SkipModelExplainabilityCheck\", \n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "register_new_baseline_model_explainability_param = ParameterBoolean(\n",
    "    name=\"RegisterNewModelExplainabilityBaseline\",\n",
    "    default_value=False\n",
    ")\n",
    "\n",
    "supplied_baseline_constraints_model_explainability_param = ParameterString(\n",
    "    name=\"ModelExplainabilitySuppliedBaselineConstraints\", \n",
    "    default_value=\"\"\n",
    ")\n",
    "\n",
    "# Set model approval param\n",
    "model_approval_status_param = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"Approved\"\n",
    ")\n",
    "\n",
    "# Set accuracy threshold\n",
    "# model performance step parameters\n",
    "threshold_param = ParameterFloat(name=\"F1Threshold\", default_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f9d353f-99ce-49f3-87f1-8352a640e555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-600187469140/mle-group7-project/data\n"
     ]
    }
   ],
   "source": [
    "# upload the data to s3 bucket\n",
    "data_s3 = sess.upload_data(path=\"./data\", key_prefix=f'{read_bucket}/{read_prefix}')\n",
    "print(data_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f5c8d9a-0084-43d9-b76b-d9cd588443b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set local path prefix in the processing container\n",
    "input_data_path = os.path.join(r\"/opt/ml/processing/input\", \"healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "# df = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "df = pd.read_csv(input_data_path)\n",
    "\n",
    "# downsize the dataframe so the model learns better in training\n",
    "df = pd.concat([df[df['stroke']==0].sample(2500), df[df['stroke']==1]])\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df[df['gender']!='Other']\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df[['gender', 'work_type', 'Residence_type', 'smoking_status']], drop_first=True)], axis=1)\n",
    "df['ever_married'] = np.where(df['ever_married']=='Yes', 1, 0)\n",
    "df['work_type_Never_worked'] = df['work_type_Never_worked'] + df['work_type_children']\n",
    "               \n",
    "df.drop(['id', 'gender', 'work_type', 'Residence_type', 'smoking_status', 'work_type_children'], axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df['stroke'], df.drop(['stroke'], axis=1)], axis=1)\n",
    "\n",
    "print(\"Shape of data is:\", df.shape)\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df['stroke'])\n",
    "test, validation = train_test_split(test, test_size=0.5, stratify=test['stroke'])\n",
    "\n",
    "# try:\n",
    "train.to_csv(r\"/opt/ml/processing/output/train/train.csv\", index=False)\n",
    "validation.to_csv(r\"/opt/ml/processing/output/validation/validation.csv\", index=False)\n",
    "test.to_csv(r\"/opt/ml/processing/output/test/test.csv\", index=False)\n",
    "df.to_csv(r\"/opt/ml/processing/output/full/df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27d61ff4-7e18-444d-90ec-5199cdfcbc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "# Upload processing script to S3\n",
    "s3_client.upload_file(\n",
    "    Filename=\"preprocessing.py\", Bucket=write_bucket, Key=f\"{write_prefix}/scripts/preprocessing.py\"\n",
    ")\n",
    "\n",
    "# Define the SKLearnProcessor configuration\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=process_instance_type,\n",
    "    base_job_name=f\"{base_job_name_prefix}-processing\",\n",
    ")\n",
    "\n",
    "# Define pipeline processing step\n",
    "process_step = ProcessingStep(\n",
    "    name=\"DataProcessing\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=data_uri, destination=\"/opt/ml/processing/input\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/train_data\", output_name=\"train_data\", source=\"/opt/ml/processing/output/train\"),\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/validation_data\", output_name=\"validation_data\", source=\"/opt/ml/processing/output/validation\"),\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/test_data\", output_name=\"test_data\", source=\"/opt/ml/processing/output/test\"),\n",
    "        ProcessingOutput(destination=f\"{processing_output_uri}/processed_data\", output_name=\"processed_data\", source=\"/opt/ml/processing/output/full\")\n",
    "    ],\n",
    "    code=f\"s3://{write_bucket}/{write_prefix}/scripts/preprocessing.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e67e453a-1358-448a-a775-a928744db475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xgboost_train.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile xgboost_train.py\n",
    "\n",
    "# import argparse\n",
    "# import os\n",
    "# import joblib\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # Hyperparameters and algorithm parameters are described here\n",
    "#     parser.add_argument(\"--num_round\", type=int, default=100)\n",
    "#     parser.add_argument(\"--max_depth\", type=int, default=3)\n",
    "#     parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "#     parser.add_argument(\"--subsample\", type=float, default=0.9)\n",
    "#     parser.add_argument(\"--colsample_bytree\", type=float, default=0.8)\n",
    "#     parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "#     parser.add_argument(\"--eval_metric\", type=str, default=\"logloss\")\n",
    "#     parser.add_argument(\"--nfold\", type=int, default=3)\n",
    "#     parser.add_argument(\"--early_stopping_rounds\", type=int, default=3)\n",
    "#     parser.add_argument(\"--alpha\", type=float, default=0)\n",
    "#     parser.add_argument(\"--min_child_weight\", type=float, default=1)\n",
    "\n",
    "#     # SageMaker specific arguments. Defaults are set in the environment variables\n",
    "#     # Set location of input training data\n",
    "#     parser.add_argument(\"--train_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "#     # Set location of input validation data\n",
    "#     parser.add_argument(\"--validation_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "#     # Set location where trained model will be stored. Default set by SageMaker, /opt/ml/model\n",
    "#     parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "#     # Set location where model artifacts will be stored. Default set by SageMaker, /opt/ml/output/data\n",
    "#     parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     data_train = pd.read_csv(f\"{args.train_data_dir}/train.csv\")\n",
    "#     train = data_train.drop(\"stroke\", axis=1)\n",
    "#     label_train = pd.DataFrame(data_train[\"stroke\"])\n",
    "#     dtrain = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    \n",
    "#     data_validation = pd.read_csv(f\"{args.validation_data_dir}/validation.csv\")\n",
    "#     validation = data_validation.drop(\"stroke\", axis=1)\n",
    "#     label_validation = pd.DataFrame(data_validation[\"stroke\"])\n",
    "#     dvalidation = xgb.DMatrix(validation, label=label_validation)\n",
    "    \n",
    "#     # Choose XGBoost model hyperparameters\n",
    "#     params = {\"max_depth\": args.max_depth,\n",
    "#               \"eta\": args.eta,\n",
    "#               \"objective\": args.objective,\n",
    "#               \"subsample\" : args.subsample,\n",
    "#               \"colsample_bytree\":args.colsample_bytree,\n",
    "#               \"alpha\" : args.alpha,\n",
    "#               \"min_child_weight\" : args.min_child_weight\n",
    "#              }\n",
    "    \n",
    "#     num_boost_round = args.num_round\n",
    "#     nfold = args.nfold\n",
    "#     early_stopping_rounds = args.early_stopping_rounds\n",
    "    \n",
    "#     # Cross-validate train XGBoost model\n",
    "#     cv_results = xgb.cv(\n",
    "#         params=params,\n",
    "#         dtrain=dtrain,\n",
    "#         num_boost_round=num_boost_round,\n",
    "#         nfold=nfold,\n",
    "#         early_stopping_rounds=early_stopping_rounds,\n",
    "#         metrics=[\"logloss\"],\n",
    "#         seed=42,\n",
    "#     )\n",
    "    \n",
    "#     model = xgb.train(params=params, dtrain=dtrain, num_boost_round=len(cv_results))\n",
    "    \n",
    "#     train_pred = np.where(model.predict(dtrain)>0.5, 1, 0)\n",
    "#     validation_pred = np.where(model.predict(dvalidation)>0.5, 1, 0)\n",
    "    \n",
    "#     train_f1_score = f1_score(label_train, train_pred)\n",
    "#     validation_f1_score = f1_score(label_validation, validation_pred)\n",
    "    \n",
    "#     print(f\"[0]#011train-f1_score:{train_f1_score:.2f}\")\n",
    "#     print(f\"[0]#011validation-f1_score:{validation_f1_score:.2f}\")\n",
    "\n",
    "#     metrics_data = {\"hyperparameters\" : params,\n",
    "#                     \"classification_metrics\": {\"validation\": {\"value\": validation_f1_score},\n",
    "#                                                       \"train\": {\"value\": train_f1_score}\n",
    "#                                                      }\n",
    "#                    }\n",
    "    \n",
    "              \n",
    "#     # Save the evaluation metrics to the location specified by output_data_dir\n",
    "#     metrics_location = args.output_data_dir + \"/metrics.json\"\n",
    "    \n",
    "#     # Save the trained model to the location specified by model_dir\n",
    "#     model_location = args.model_dir + \"/xgboost-model\"\n",
    "\n",
    "#     with open(metrics_location, \"w\") as f:\n",
    "#         json.dump(metrics_data, f)\n",
    "\n",
    "#     with open(model_location, \"wb\") as f:\n",
    "#         joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0d67367-59e4-4f28-aa56-77ab7c95d4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set XGBoost model hyperparameters \n",
    "hyperparams = {  \n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": 5,\n",
    "    \"max_depth\":5,\n",
    "    \"subsample\":0.75,\n",
    "    \"colsample_bytree\":0.75,\n",
    "    \"eta\":0.5,\n",
    "    \"alpha\" : 0,\n",
    "    \"min_child_weight\" : 1\n",
    "}\n",
    "\n",
    "# Set XGBoost estimator\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgboost_train.py\", \n",
    "    output_path=estimator_output_uri,\n",
    "    code_location=estimator_output_uri,\n",
    "    hyperparameters=hyperparams,\n",
    "    role=sagemaker_role,\n",
    "    # Fetch instance type and count from pipeline parameters\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    framework_version=\"1.3-1\"\n",
    ")\n",
    "\n",
    "# Access the location where the preceding processing step saved train and validation datasets\n",
    "# Pipeline step properties can give access to outputs which can be used in succeeding steps\n",
    "s3_input_train = TrainingInput(\n",
    "    s3_data=process_step.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri, \n",
    "    content_type=\"csv\", \n",
    "    s3_data_type=\"S3Prefix\"\n",
    ")\n",
    "\n",
    "s3_input_validation = TrainingInput(\n",
    "    s3_data=process_step.properties.ProcessingOutputConfig.Outputs[\"validation_data\"].S3Output.S3Uri,\n",
    "    content_type=\"csv\",\n",
    "    s3_data_type=\"S3Prefix\"\n",
    ")\n",
    "\n",
    "# Set pipeline training step\n",
    "train_step = TrainingStep(\n",
    "    name=\"XGBModelTraining\",\n",
    "    estimator=xgb_estimator,\n",
    "    inputs={\n",
    "    \"train\":s3_input_train, # Train channel \n",
    "    \"validation\": s3_input_validation # Validation channel\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7cc61-c83a-449a-ac2a-a562a1ec957f",
   "metadata": {},
   "source": [
    "Tuning Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dad45f3a-4803-48e4-8301-a43098b23898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.parameter import ContinuousParameter, IntegerParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.estimator import Estimator\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=training_image,\n",
    "    instance_type=train_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=estimator_output_uri,\n",
    "    base_job_name=f\"{base_job_name_prefix}\",\n",
    "    sagemaker_session=sess,\n",
    "    role=sagemaker_role ,\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"binary:logistic\",  # Define the object metric for the training job\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    alpha=0\n",
    ")\n",
    "\n",
    "objective_metric_name = \"validation:f1\"\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0.01,10,scaling_type=\"Logarithmic\"),\n",
    "    \"min_child_weight\": IntegerParameter(1,10),\n",
    "    \"max_depth\": IntegerParameter(1,10),\n",
    "    \"eta\": ContinuousParameter(0.01,1,scaling_type=\"Logarithmic\")\n",
    "    } \n",
    "\n",
    "tuner = HyperparameterTuner(xgb_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs = 3,\n",
    "                            max_parallel_jobs = 3,\n",
    "                            strategy=\"Bayesian\",\n",
    "                            objective_type=\"Maximize\",\n",
    "                            random_seed = 123)\n",
    "\n",
    "logger.debug(\"Tune the model.\")\n",
    "tuning_step = TuningStep(\n",
    "    name = \"XGBModelTuning\",\n",
    "    tuner = tuner,\n",
    "    inputs = {\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=process_step.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri, \n",
    "            content_type=\"csv\", \n",
    "            s3_data_type=\"S3Prefix\"),\n",
    "        # \"train\" : train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=process_step.properties.ProcessingOutputConfig.Outputs[\"validation_data\"].S3Output.S3Uri,\n",
    "            content_type=\"csv\",\n",
    "            s3_data_type=\"S3Prefix\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2501b5a6-2287-4740-9a3c-608b486c007e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "# Create a SageMaker model\n",
    "logger.debug(\"Define best model.\")\n",
    "best_model = sagemaker.model.Model(\n",
    "    image_uri = training_image,\n",
    "    model_data = tuning_step.get_top_model_s3_uri(\n",
    "                top_k = 0,\n",
    "                s3_bucket = write_bucket,\n",
    "                prefix= f'{write_prefix}/training_jobs'\n",
    "                ),\n",
    "    sagemaker_session=sess,\n",
    "    role=sagemaker_role\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebbde552-7b68-48e2-97f0-ecbf6f50c99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "# Specify model deployment instance type\n",
    "inputs = sagemaker.inputs.CreateModelInput(instance_type=deploy_instance_type_param)\n",
    "\n",
    "create_model_step = CreateModelStep(name=\"StrokePredictionModel\", model=best_model, inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cef84ed-3a90-4292-8863-779646cc03f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up common configuration parameters to be used across multiple steps\n",
    "check_job_config = CheckJobConfig(\n",
    "    role=sagemaker_role,\n",
    "    instance_count=1,\n",
    "    instance_type=clarify_instance_type,\n",
    "    volume_size_in_gb=30,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Set up configuration of data to be used for model bias check\n",
    "model_bias_data_config = sagemaker.clarify.DataConfig(\n",
    "    # Fetch S3 location where processing step saved train data\n",
    "    s3_data_input_path=process_step.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri,\n",
    "    s3_output_path=bias_report_output_uri,\n",
    "    label=target_col,\n",
    "    dataset_type=\"text/csv\",\n",
    "    s3_analysis_config_output_path=clarify_bias_config_output_uri\n",
    ")\n",
    "\n",
    "# Set up details of the trained model to be checked for bias\n",
    "model_config = sagemaker.clarify.ModelConfig(\n",
    "    # Pull model name from model creation step\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type\n",
    ")\n",
    "\n",
    "# Set up column and categories that are to be checked for bias\n",
    "model_bias_config = sagemaker.clarify.BiasConfig(\n",
    "    label_values_or_threshold=[0],\n",
    "    facet_name=\"gender_Male\",\n",
    "    facet_values_or_threshold=[1]\n",
    ")\n",
    "\n",
    "# Set up model predictions configuration to get binary labels from probabilities\n",
    "model_predictions_config = sagemaker.clarify.ModelPredictedLabelConfig(probability_threshold=0.5)\n",
    "\n",
    "model_bias_check_config = ModelBiasCheckConfig(\n",
    "    data_config=model_bias_data_config,\n",
    "    data_bias_config=model_bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=model_predictions_config,\n",
    "    methods=[\"DPPL\"]\n",
    ")\n",
    "\n",
    "# Set up pipeline model bias check step\n",
    "model_bias_check_step = ClarifyCheckStep(\n",
    "    name=\"ModelBiasCheck\",\n",
    "    clarify_check_config=model_bias_check_config,\n",
    "    check_job_config=check_job_config,\n",
    "    skip_check=skip_check_model_bias_param,\n",
    "    register_new_baseline=register_new_baseline_model_bias_param,\n",
    "    supplied_baseline_constraints=supplied_baseline_constraints_model_bias_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "86f38988-e094-4885-bbfd-fbfc33f0c571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set configuration of data to be used for model explainability check\n",
    "model_explainability_data_config = sagemaker.clarify.DataConfig(\n",
    "    # Fetch S3 location where processing step saved train data\n",
    "    s3_data_input_path=process_step.properties.ProcessingOutputConfig.Outputs[\"train_data\"].S3Output.S3Uri,\n",
    "    s3_output_path=explainability_report_output_uri,\n",
    "    label=target_col,\n",
    "    dataset_type=\"text/csv\",\n",
    "    s3_analysis_config_output_path=clarify_explainability_config_output_uri \n",
    ")\n",
    "\n",
    "# Set SHAP configuration for Clarify to compute global and local SHAP values for feature importance\n",
    "shap_config = sagemaker.clarify.SHAPConfig(\n",
    "    seed=42, \n",
    "    num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True\n",
    ")\n",
    "\n",
    "model_explainability_config = ModelExplainabilityCheckConfig(\n",
    "    data_config=model_explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")\n",
    "\n",
    "# Set pipeline model explainability check step\n",
    "model_explainability_step = ClarifyCheckStep(\n",
    "    name=\"ModelExplainabilityCheck\",\n",
    "    clarify_check_config=model_explainability_config,\n",
    "    check_job_config=check_job_config,\n",
    "    skip_check=skip_check_model_explainability_param,\n",
    "    register_new_baseline=register_new_baseline_model_explainability_param,\n",
    "    supplied_baseline_constraints=supplied_baseline_constraints_model_explainability_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1689c04-4c25-48ab-b218-805df729e031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "feature_columns = [\n",
    "    \"age\",\n",
    "    \"hypertension\",\n",
    "    \"heart_disease\",\n",
    "    \"ever_married\",\n",
    "    \"avg_glucose_level\",\n",
    "    \"bmi\",\n",
    "    \"gender_Male\",\n",
    "    \"work_type_Never_worked\",\n",
    "    \"work_type_Private\",\n",
    "    \"work_type_Self-employed\",\n",
    "    \"Residence_type_Urban\",\n",
    "    \"smoking_status_formerly smoked\",\n",
    "    \"smoking_status_never smoked\",\n",
    "    \"smoking_status_smokes\"\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    logger.debug(\"Loading xgboost model.\")\n",
    "    # The name of the file should match how the model was saved in the training script\n",
    "    model = xgb.Booster()\n",
    "    model.load_model('xgboost-model')\n",
    "    # model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    logger.debug(\"Reading test data.\")\n",
    "    test_local_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df_test = pd.read_csv(test_local_path)\n",
    "    \n",
    "    # Extract test set target column\n",
    "    y_test = df_test.iloc[:, 0].values\n",
    "   \n",
    "    # cols_when_train = model.feature_names\n",
    "    cols_when_train = feature_columns\n",
    "    # Extract test set feature columns\n",
    "    X = df_test[cols_when_train].copy()\n",
    "    X_test = xgb.DMatrix(X)\n",
    "\n",
    "    logger.info(\"Generating predictions for test data.\")\n",
    "    pred = np.where(model.predict(X_test)>0.5, 1, 0)\n",
    "    \n",
    "    # Calculate model evaluation score\n",
    "    logger.debug(\"Calculating f1_score score.\")\n",
    "    score = f1_score(y_test, pred)\n",
    "    metric_dict = {\n",
    "        \"classification_metrics\": {\"f1_score\": {\"value\": score}}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Save model evaluation metrics\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Writing evaluation report with f1_score: %f\", score)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(metric_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7415ff84-576a-4c79-8045-b7d4de7e19ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload model evaluation script to S3\n",
    "s3_client.upload_file(\n",
    "    Filename=\"evaluate.py\", Bucket=write_bucket, Key=f\"{write_prefix}/scripts/evaluate.py\"\n",
    ")\n",
    "\n",
    "eval_processor = ScriptProcessor(\n",
    "    image_uri=training_image,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=predictor_instance_type,\n",
    "    instance_count=predictor_instance_count,\n",
    "    base_job_name=f\"{base_job_name_prefix}-model-eval\",\n",
    "    sagemaker_session=sess,\n",
    "    role=sagemaker_role,\n",
    ")\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"StrokePredictionEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "# Set model evaluation step\n",
    "evaluation_step = ProcessingStep(\n",
    "    name=\"XGBModelEvaluate\",\n",
    "    processor=eval_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            # Fetch S3 location where train step saved model artifacts\n",
    "            # source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            source=tuning_step.get_top_model_s3_uri(\n",
    "                top_k = 0,\n",
    "                s3_bucket = write_bucket,\n",
    "                prefix= f'{write_prefix}/training_jobs'\n",
    "                ),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            # Fetch S3 location where processing step saved test data\n",
    "            source=process_step.properties.ProcessingOutputConfig.Outputs[\"test_data\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(destination=f\"{model_eval_output_uri}\", output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=f\"s3://{write_bucket}/{write_prefix}/scripts/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5780f8fc-1061-48b9-ba59-3c3e40108aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch baseline constraints to record in model registry\n",
    "model_metrics = ModelMetrics(\n",
    "    bias_post_training=MetricsSource(\n",
    "        s3_uri=model_bias_check_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\"\n",
    "    ),\n",
    "    explainability=MetricsSource(\n",
    "        s3_uri=model_explainability_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Fetch baselines to record in model registry for drift check\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    bias_post_training_constraints=MetricsSource(\n",
    "        s3_uri=model_bias_check_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    explainability_constraints=MetricsSource(\n",
    "        s3_uri=model_explainability_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    explainability_config_file=FileSource(\n",
    "        s3_uri=model_explainability_config.monitoring_analysis_config_uri,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define register model step\n",
    "register_step = RegisterModel(\n",
    "    name=\"XGBRegisterModel\",\n",
    "    estimator=xgb_estimator,\n",
    "    # Fetching S3 location where train step saved model artifacts\n",
    "    # model_data=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    model_data=tuning_step.get_top_model_s3_uri(\n",
    "                top_k = 0,\n",
    "                s3_bucket = write_bucket,\n",
    "                prefix= f'{write_prefix}/training_jobs'\n",
    "                ),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[predictor_instance_type],\n",
    "    transform_instances=[predictor_instance_type],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status_param,\n",
    "    # Registering baselines metrics that can be used for model monitoring\n",
    "    model_metrics=model_metrics,\n",
    "    drift_check_baselines=drift_check_baselines\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "babef4ec-8571-4122-a427-af1438cde40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_deployer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_deployer.py\n",
    "\n",
    "\"\"\"\n",
    "Lambda function creates an endpoint configuration and deploys a model to real-time endpoint. \n",
    "Required parameters for deployment are retrieved from the event object\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # Details of the model created in the Pipeline CreateModelStep\n",
    "    model_name = event[\"model_name\"]\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    endpoint_config_name = event[\"endpoint_config_name\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    role = event[\"role\"]\n",
    "    instance_type = event[\"instance_type\"]\n",
    "    instance_count = event[\"instance_count\"]\n",
    "    primary_container = {\"ModelPackageName\": model_package_arn}\n",
    "\n",
    "    # Create model\n",
    "    model = sm_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        PrimaryContainer=primary_container,\n",
    "        ExecutionRoleArn=role\n",
    "    )\n",
    "\n",
    "    # Create endpoint configuration\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"Alltraffic\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InitialInstanceCount\": instance_count,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialVariantWeight\": 1\n",
    "        }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create endpoint\n",
    "    create_endpoint_response = sm_client.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2cdc6d1d-3d84-4ec4-85cb-048a53f4557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function name must contain sagemaker\n",
    "function_name = \"sagemaker-stroke-prediction-demo-lambda-step\"\n",
    "# Define Lambda helper class can be used to create the Lambda function required in the Lambda step\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=sagemaker_role,\n",
    "    script=\"lambda_deployer.py\",\n",
    "    handler=\"lambda_deployer.lambda_handler\",\n",
    "    timeout=600,\n",
    "    memory_size=10240,\n",
    ")\n",
    "\n",
    "# The inputs used in the lambda handler are passed through the inputs argument in the \n",
    "# LambdaStep and retrieved via the `event` object within the `lambda_handler` function\n",
    "\n",
    "lambda_deploy_step = LambdaStep(\n",
    "    name=\"LambdaStepRealTimeDeploy\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"model_name\": pipeline_model_name,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"model_package_arn\": register_step.steps[0].properties.ModelPackageArn,\n",
    "        \"role\": sagemaker_role,\n",
    "        \"instance_type\": deploy_instance_type_param,\n",
    "        \"instance_count\": deploy_instance_count_param\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2820479c-acf9-4df0-8fbe-73a181d54a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance on test set\n",
    "cond_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.f1_score.value\", \n",
    "    ),\n",
    "    right=threshold_param, # Threshold to compare model performance against\n",
    ")\n",
    "condition_step = ConditionStep(\n",
    "    name=\"CheckStrokeDetectionXGBEvaluation\",\n",
    "    conditions=[cond_gte],\n",
    "    if_steps=[create_model_step, model_bias_check_step, model_explainability_step, register_step, lambda_deploy_step], \n",
    "    else_steps=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "659f1bb6-fd25-4fb9-a471-3308298c8940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Pipeline with all component steps and parameters\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[process_instance_type_param, \n",
    "                train_instance_type_param, \n",
    "                train_instance_count_param, \n",
    "                deploy_instance_type_param,\n",
    "                deploy_instance_count_param,\n",
    "                threshold_param,\n",
    "                clarify_instance_type_param,\n",
    "                skip_check_model_bias_param,\n",
    "                register_new_baseline_model_bias_param,\n",
    "                supplied_baseline_constraints_model_bias_param,\n",
    "                skip_check_model_explainability_param,\n",
    "                register_new_baseline_model_explainability_param,\n",
    "                supplied_baseline_constraints_model_explainability_param,\n",
    "                model_approval_status_param],\n",
    "    steps=[\n",
    "        process_step,\n",
    "        # train_step,\n",
    "        tuning_step,\n",
    "        evaluation_step,\n",
    "        condition_step\n",
    "    ],\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34b46d14-5dfb-43b9-b703-c628e71f2f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.c5.xlarge'},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m4.xlarge'},\n",
       "  {'Name': 'TrainingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'DeployInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m4.xlarge'},\n",
       "  {'Name': 'DeployInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'AccuracyThreshold', 'Type': 'Float', 'DefaultValue': 0.0},\n",
       "  {'Name': 'ClarifyInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m4.xlarge'},\n",
       "  {'Name': 'SkipModelBiasCheck', 'Type': 'Boolean', 'DefaultValue': False},\n",
       "  {'Name': 'RegisterNewModelBiasBaseline',\n",
       "   'Type': 'Boolean',\n",
       "   'DefaultValue': False},\n",
       "  {'Name': 'ModelBiasSuppliedBaselineConstraints',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': ''},\n",
       "  {'Name': 'SkipModelExplainabilityCheck',\n",
       "   'Type': 'Boolean',\n",
       "   'DefaultValue': False},\n",
       "  {'Name': 'RegisterNewModelExplainabilityBaseline',\n",
       "   'Type': 'Boolean',\n",
       "   'DefaultValue': False},\n",
       "  {'Name': 'ModelExplainabilitySuppliedBaselineConstraints',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': ''},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'Approved'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'DataProcessing',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.c5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocessing.py']},\n",
       "    'RoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/mle-group7-project/data/healthcare-dataset-stroke-data.csv',\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/scripts/preprocessing.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/processing_jobs/train_data',\n",
       "        'LocalPath': '/opt/ml/processing/output/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation_data',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/processing_jobs/validation_data',\n",
       "        'LocalPath': '/opt/ml/processing/output/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test_data',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/processing_jobs/test_data',\n",
       "        'LocalPath': '/opt/ml/processing/output/test',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'processed_data',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/processing_jobs/processed_data',\n",
       "        'LocalPath': '/opt/ml/processing/output/full',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'XGBModelTuning',\n",
       "   'Type': 'Tuning',\n",
       "   'Arguments': {'HyperParameterTuningJobConfig': {'Strategy': 'Bayesian',\n",
       "     'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "      'MaxParallelTrainingJobs': 3},\n",
       "     'TrainingJobEarlyStoppingType': 'Off',\n",
       "     'RandomSeed': 123,\n",
       "     'HyperParameterTuningJobObjective': {'Type': 'Maximize',\n",
       "      'MetricName': 'validation:f1'},\n",
       "     'ParameterRanges': {'ContinuousParameterRanges': [{'Name': 'alpha',\n",
       "        'MinValue': '0.01',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Logarithmic'},\n",
       "       {'Name': 'eta',\n",
       "        'MinValue': '0.01',\n",
       "        'MaxValue': '1',\n",
       "        'ScalingType': 'Logarithmic'}],\n",
       "      'CategoricalParameterRanges': [],\n",
       "      'IntegerParameterRanges': [{'Name': 'min_child_weight',\n",
       "        'MinValue': '1',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Auto'},\n",
       "       {'Name': 'max_depth',\n",
       "        'MinValue': '1',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Auto'}]}},\n",
       "    'TrainingJobDefinition': {'StaticHyperParameters': {'eval_metric': 'logloss',\n",
       "      'objective': 'binary:logistic',\n",
       "      'num_round': '50',\n",
       "      'gamma': '4',\n",
       "      'subsample': '0.7'},\n",
       "     'RoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "     'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/training_jobs'},\n",
       "     'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "     'HyperParameterTuningResourceConfig': {'InstanceCount': 1,\n",
       "      'InstanceType': 'ml.m4.xlarge',\n",
       "      'VolumeSizeInGB': 30},\n",
       "     'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "      'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1'},\n",
       "     'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "         'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri\"},\n",
       "         'S3DataDistributionType': 'FullyReplicated'}},\n",
       "       'ContentType': 'csv',\n",
       "       'ChannelName': 'train'},\n",
       "      {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "         'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['validation_data'].S3Output.S3Uri\"},\n",
       "         'S3DataDistributionType': 'FullyReplicated'}},\n",
       "       'ContentType': 'csv',\n",
       "       'ChannelName': 'validation'}]}}},\n",
       "  {'Name': 'XGBModelEvaluate',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "         'Values': ['s3:/',\n",
       "          'sagemaker-us-east-1-600187469140',\n",
       "          'stroke-prediction/training_jobs',\n",
       "          {'Get': 'Steps.XGBModelTuning.TrainingJobSummaries[0].TrainingJobName'},\n",
       "          'output/model.tar.gz']}},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['test_data'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/scripts/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/model_eval',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'StrokePredictionEvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'CheckStrokeDetectionXGBEvaluation',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'GreaterThanOrEqualTo',\n",
       "      'LeftValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.XGBModelEvaluate.PropertyFiles.StrokePredictionEvaluationReport'},\n",
       "        'Path': 'classification_metrics.f1_score.value'}},\n",
       "      'RightValue': {'Get': 'Parameters.AccuracyThreshold'}}],\n",
       "    'IfSteps': [{'Name': 'StrokePredictionModel',\n",
       "      'Type': 'Model',\n",
       "      'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "       'PrimaryContainer': {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "        'Environment': {},\n",
       "        'ModelDataUrl': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3:/',\n",
       "           'sagemaker-us-east-1-600187469140',\n",
       "           'stroke-prediction/training_jobs',\n",
       "           {'Get': 'Steps.XGBModelTuning.TrainingJobSummaries[0].TrainingJobName'},\n",
       "           'output/model.tar.gz']}}}}},\n",
       "     {'Name': 'ModelBiasCheck',\n",
       "      'Type': 'ClarifyCheck',\n",
       "      'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "         'InstanceCount': 1,\n",
       "         'VolumeSizeInGB': 30}},\n",
       "       'AppSpecification': {'ImageUri': '205585389593.dkr.ecr.us-east-1.amazonaws.com/sagemaker-clarify-processing:1.0'},\n",
       "       'RoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "       'ProcessingInputs': [{'InputName': 'analysis_config',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/model_monitor/bias_config/analysis_config.json',\n",
       "          'LocalPath': '/opt/ml/processing/input/config',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}},\n",
       "        {'InputName': 'dataset',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri\"},\n",
       "          'LocalPath': '/opt/ml/processing/input/data',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}}],\n",
       "       'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'analysis_result',\n",
       "          'AppManaged': False,\n",
       "          'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/clarify_output/pipeline/bias',\n",
       "           'LocalPath': '/opt/ml/processing/output',\n",
       "           'S3UploadMode': 'EndOfJob'}}]}},\n",
       "      'CheckType': 'MODEL_BIAS',\n",
       "      'ModelPackageGroupName': None,\n",
       "      'SkipCheck': {'Get': 'Parameters.SkipModelBiasCheck'},\n",
       "      'FailOnViolation': True,\n",
       "      'RegisterNewBaseline': {'Get': 'Parameters.RegisterNewModelBiasBaseline'},\n",
       "      'SuppliedBaselineConstraints': {'Get': 'Parameters.ModelBiasSuppliedBaselineConstraints'},\n",
       "      'ModelName': {'Get': 'Steps.StrokePredictionModel.ModelName'}},\n",
       "     {'Name': 'ModelExplainabilityCheck',\n",
       "      'Type': 'ClarifyCheck',\n",
       "      'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "         'InstanceCount': 1,\n",
       "         'VolumeSizeInGB': 30}},\n",
       "       'AppSpecification': {'ImageUri': '205585389593.dkr.ecr.us-east-1.amazonaws.com/sagemaker-clarify-processing:1.0'},\n",
       "       'RoleArn': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "       'ProcessingInputs': [{'InputName': 'analysis_config',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/model_monitor/explainability_config/analysis_config.json',\n",
       "          'LocalPath': '/opt/ml/processing/input/config',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}},\n",
       "        {'InputName': 'dataset',\n",
       "         'AppManaged': False,\n",
       "         'S3Input': {'S3Uri': {'Get': \"Steps.DataProcessing.ProcessingOutputConfig.Outputs['train_data'].S3Output.S3Uri\"},\n",
       "          'LocalPath': '/opt/ml/processing/input/data',\n",
       "          'S3DataType': 'S3Prefix',\n",
       "          'S3InputMode': 'File',\n",
       "          'S3DataDistributionType': 'FullyReplicated',\n",
       "          'S3CompressionType': 'None'}}],\n",
       "       'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'analysis_result',\n",
       "          'AppManaged': False,\n",
       "          'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/clarify_output/pipeline/explainability',\n",
       "           'LocalPath': '/opt/ml/processing/output',\n",
       "           'S3UploadMode': 'EndOfJob'}}]}},\n",
       "      'CheckType': 'MODEL_EXPLAINABILITY',\n",
       "      'ModelPackageGroupName': None,\n",
       "      'SkipCheck': {'Get': 'Parameters.SkipModelExplainabilityCheck'},\n",
       "      'FailOnViolation': True,\n",
       "      'RegisterNewBaseline': {'Get': 'Parameters.RegisterNewModelExplainabilityBaseline'},\n",
       "      'SuppliedBaselineConstraints': {'Get': 'Parameters.ModelExplainabilitySuppliedBaselineConstraints'},\n",
       "      'ModelName': {'Get': 'Steps.StrokePredictionModel.ModelName'}},\n",
       "     {'Name': 'XGBRegisterModel-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'stroke-prediction-xgb-model-group',\n",
       "       'ModelMetrics': {'Bias': {'PostTrainingReport': {'ContentType': 'application/json',\n",
       "          'S3Uri': {'Get': 'Steps.ModelBiasCheck.CalculatedBaselineConstraints'}}},\n",
       "        'Explainability': {'Report': {'ContentType': 'application/json',\n",
       "          'S3Uri': {'Get': 'Steps.ModelExplainabilityCheck.CalculatedBaselineConstraints'}}}},\n",
       "       'DriftCheckBaselines': {'Bias': {'PostTrainingConstraints': {'ContentType': 'application/json',\n",
       "          'S3Uri': {'Get': 'Steps.ModelBiasCheck.BaselineUsedForDriftCheckConstraints'}}},\n",
       "        'Explainability': {'Constraints': {'ContentType': 'application/json',\n",
       "          'S3Uri': {'Get': 'Steps.ModelExplainabilityCheck.BaselineUsedForDriftCheckConstraints'}},\n",
       "         'ConfigFile': {'S3Uri': 's3://sagemaker-us-east-1-600187469140/stroke-prediction/model_monitor/explainability_config/model-explainability-monitoring-configuration/model-explainability-monitoring-config-2023-06-18-02-42-33-649/cb8d7342-2d95-4de1-b4ab-823d96a1c5de/analysis_config.json',\n",
       "          'ContentType': 'application/json'}}},\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.3-1',\n",
       "          'ModelDataUrl': {'Std:Join': {'On': '/',\n",
       "            'Values': ['s3:/',\n",
       "             'sagemaker-us-east-1-600187469140',\n",
       "             'stroke-prediction/training_jobs',\n",
       "             {'Get': 'Steps.XGBModelTuning.TrainingJobSummaries[0].TrainingJobName'},\n",
       "             'output/model.tar.gz']}}}],\n",
       "        'SupportedContentTypes': ['text/csv'],\n",
       "        'SupportedResponseMIMETypes': ['text/csv'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m4.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m4.xlarge']},\n",
       "       'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'}}},\n",
       "     {'Name': 'LambdaStepRealTimeDeploy',\n",
       "      'Type': 'Lambda',\n",
       "      'Arguments': {'model_name': 'stroke-prediction-xgb-pipeline',\n",
       "       'endpoint_config_name': 'stroke-prediction-xgb-pipeline-endpoint-config',\n",
       "       'endpoint_name': 'stroke-prediction-xgb-pipeline-endpoint',\n",
       "       'model_package_arn': {'Get': 'Steps.XGBRegisterModel-RegisterModel.ModelPackageArn'},\n",
       "       'role': 'arn:aws:iam::600187469140:role/LabRole',\n",
       "       'instance_type': {'Get': 'Parameters.DeployInstanceType'},\n",
       "       'instance_count': {'Get': 'Parameters.DeployInstanceCount'}},\n",
       "      'FunctionArn': 'arn:aws:lambda:us-east-1:600187469140:function:sagemaker-stroke-prediction-demo-lambda-step',\n",
       "      'OutputParameters': []}],\n",
       "    'ElseSteps': []}}]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new or update existing Pipeline\n",
    "pipeline.upsert(role_arn=sagemaker_role)\n",
    "\n",
    "# Full Pipeline description\n",
    "pipeline_definition = json.loads(pipeline.describe()['PipelineDefinition'])\n",
    "pipeline_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2021199b-6f66-4454-896f-8e31c7836c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "WaiterError",
     "evalue": "Waiter PipelineExecutionComplete failed: Max attempts exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-6ca188a0282f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mstart_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mwaiter_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         )\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPipelineExecutionArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mWaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     wait.__doc__ = WaiterDocstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                     \u001b[0mlast_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 )\n\u001b[1;32m    393\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter PipelineExecutionComplete failed: Max attempts exceeded"
     ]
    }
   ],
   "source": [
    "# Start the pipeline execution\n",
    "# execution = pipeline.start()\n",
    "# execution.wait()\n",
    "\n",
    "start_response = pipeline.start(parameters=dict(\n",
    "        SkipModelBiasCheck=True,\n",
    "        RegisterNewModelBiasBaseline=True,\n",
    "        SkipModelExplainabilityCheck=True,\n",
    "        RegisterNewModelExplainabilityBaseline=True)\n",
    "                               )\n",
    "\n",
    "start_response.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28c514-d117-470e-a954-3eec66950783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the Lambda function\n",
    "func.delete()\n",
    "\n",
    "# Delete the endpoint\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# Delete the EndpointConfig\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete the model\n",
    "sm_client.delete_model(ModelName=pipeline_model_name)\n",
    "\n",
    "# Delete the pipeline\n",
    "sm_client.delete_pipeline(PipelineName=pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a1e3668b-df13-472c-a4e7-f3d6207ff3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # for testing of f1_score on valid and test data\n",
    "\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # train = pd.read_csv('train.csv')\n",
    "# valid = pd.read_csv('validation.csv')\n",
    "# # test = pd.read_csv('test.csv')\n",
    "\n",
    "# xgb_model = xgb.Booster()\n",
    "# xgb_model.load_model('xgboost-model')\n",
    "\n",
    "# pred = np.where(xgb_model.predict(xgb.DMatrix(valid.drop(['stroke'], axis=1)))>0.5, 1, 0)\n",
    "# # pred = np.where(xgb_model.predict(xgb.DMatrix(test.drop(['stroke'], axis=1)))>0.5, 1, 0)\n",
    "\n",
    "# f1_score(pred, valid['stroke'])\n",
    "# # f1_score(pred, test['stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943b4c4-8406-4e2c-bcc4-4734c502f662",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-telegram-bot in /opt/conda/lib/python3.7/site-packages (20.3)\n",
      "Requirement already satisfied: httpx~=0.24.0 in /opt/conda/lib/python3.7/site-packages (from python-telegram-bot) (0.24.1)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from httpx~=0.24.0->python-telegram-bot) (0.17.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from httpx~=0.24.0->python-telegram-bot) (2022.12.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from httpx~=0.24.0->python-telegram-bot) (2.8)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.7/site-packages (from httpx~=0.24.0->python-telegram-bot) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx~=0.24.0->python-telegram-bot) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.7/site-packages (from httpcore<0.18.0,>=0.15.0->httpx~=0.24.0->python-telegram-bot) (3.6.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx~=0.24.0->python-telegram-bot) (4.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "2023-06-17 07:29:22,851 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getMe \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:22,938 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/deleteWebhook \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:22,939 - telegram.ext.Application - INFO - Application started\n",
      "2023-06-17 07:29:23,201 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:23,488 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:33,296 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:43,388 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:53,338 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:29:53,340 - __main__ - INFO - Gender of SQ: Boy\n",
      "2023-06-17 07:29:53,790 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:03,433 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:13,525 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:23,626 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:33,716 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:43,807 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:30:53,897 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:03,993 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:14,089 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:24,185 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:34,276 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:44,369 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:31:54,464 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:04,561 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:14,652 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:24,741 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:34,834 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:44,927 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:32:55,015 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:05,103 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:15,199 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:25,290 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:35,379 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:45,469 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:33:55,558 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:34:05,649 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:34:10,584 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:34:10,586 - __main__ - INFO - User SQ did not send a photo.\n",
      "2023-06-17 07:34:11,069 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2023-06-17 07:34:20,688 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot5995304835:AAEej9qI-jAGSOLhwAyP1cnDVOzpUGlVacU/getUpdates \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "!python 'TeleBot.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961dc5b4-ab24-44bf-bc77-046ddb08700b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
